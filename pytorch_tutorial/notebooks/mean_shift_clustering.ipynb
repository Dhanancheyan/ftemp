{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"PyTorch is a python package that provides [...]\n",
    "Tensor computation (like numpy) with strong GPU acceleration [...]\"\n",
    "\n",
    "So, let's use it for some Mean-shift clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean shitft clustering with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 6\n",
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate our data, we're going to pick `n_clusters` random points, which we'll call centroids, and for each point we're going to generate `n_samples` random points about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = np.random.uniform(-35, 35, (n_clusters, 2))\n",
    "slices = [np.random.multivariate_normal(centroids[i], np.diag([5., 5.]), n_samples)\n",
    "          for i in range(n_clusters)]\n",
    "data = np.concatenate(slices).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data and the centroids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(centroids, data, n_samples):\n",
    "    colour = plt.cm.rainbow(np.linspace(0,1,len(centroids)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    for i, centroid in enumerate(centroids):\n",
    "        samples = data[i * n_samples : (i + 1) * n_samples]\n",
    "        ax.scatter(samples[:, 0], samples[:, 1], c=colour[i], s=1)\n",
    "        ax.plot(centroid[0], centroid[1], markersize=10, marker=\"x\", color='k', mew=5)\n",
    "        ax.plot(centroid[0], centroid[1], markersize=5, marker=\"x\", color='m', mew=2)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "plot_data(centroids, data, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The mean shift algorithm\n",
    "\n",
    "\"Mean shift is a **non-parametric** feature-space analysis technique for locating the maxima of a density function, a so-called **mode-seeking algorithm**. Application domains include cluster analysis in computer vision and image processing.\" -- https://en.wikipedia.org/wiki/Mean_shift\n",
    "\n",
    "Think of mean-shift clustering as k-means but you don't have to specify the number of clusters.\n",
    "(You have to specify the **bandwidth** but that can be automated.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo:\n",
    "```python\n",
    "# PSEUDO CODE\n",
    "while not_converged():\n",
    "    for i, point in enumerate(points):\n",
    "        # distance for the given point to all other points\n",
    "        distances = calc_distances(point, points)\n",
    "        \n",
    "        # turn distance into weights using a gaussian\n",
    "        weights = gaussian(dist, bandwidth=2.5)\n",
    "        \n",
    "        # update the weights by using the weights\n",
    "        points[i] = (weights * points).sum(0) / weights.sum()\n",
    "\n",
    "return points\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The implementation\n",
    "\n",
    "Let's implement this with numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp, sqrt, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x, X):\n",
    "    # return np.linalg.norm(x - X, axis=1)\n",
    "    return sqrt(((x - X)**2).sum(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out. (More on how this function works shortly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = array([1, 2])\n",
    "b = array([[1, 2],\n",
    "           [2, 3],\n",
    "           [-1, -3]])\n",
    "\n",
    "dist = distance(a, b)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(dist, bandwidth):\n",
    "    return exp(-0.5 * ((dist / bandwidth))**2) / (bandwidth * math.sqrt(2 * math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian(dist, 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a single mean shift step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift_step(X, bandwidth=2.5):\n",
    "    for i, x in enumerate(X):\n",
    "        dist = distance(x, X)\n",
    "        weight = gaussian(dist, bandwidth)\n",
    "        X[i] = (weight[:, None] * X).sum(0) / weight.sum()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(centroids, data, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = meanshift_step(np.copy(data))\n",
    "plot_data(centroids, _X, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just repeath this/iterate a few times and we have the complete mean shift algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift(X):\n",
    "    X = np.copy(X)\n",
    "    for _ in range(5):\n",
    "        X = meanshift_step(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = meanshift(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(centroids, X, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean shift in PyTorch (with GPU)\n",
    "\n",
    "PyTorch is like numpy and the interface is very similar.\n",
    "\n",
    "We actually don't have to adjust anything really to use torch instead of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import exp, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We oncly have to copy the data into a PyTorch GPU tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift_torch(X):\n",
    "    X = torch.from_numpy(np.copy(X)).cuda()\n",
    "    for it in range(5):\n",
    "        X = meanshift_step(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch(data).cpu().numpy()\n",
    "plot_data(centroids+2, X, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same results, but the implementation is about the same speed.\n",
    "\n",
    "CUDA kernels have to be started for each calculation and the kernels don't have enough to do.\n",
    "Let's not process individual points, but batches of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_batch(a, b):\n",
    "    return sqrt(((a[None,:] - b[:,None]) ** 2).sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(3, 2)\n",
    "distance_batch(b, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`distance_batch` contains some broadcast magic that allows us to compute the distance from each point in a batch to all points in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanshift_torch2(data, batch_size=500):\n",
    "    n = len(data)\n",
    "    X = torch.from_numpy(np.copy(data)).cuda()\n",
    "    for _ in range(5):\n",
    "        for i in range(0, n, batch_size):\n",
    "            s = slice(i, min(n, i + batch_size))\n",
    "            weight = gaussian(distance_batch(X, X[s]), 2.5)\n",
    "            num = (weight[:, :, None] * X).sum(dim=1)\n",
    "            X[s] = num / weight.sum(1)[:, None]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch2(data, batch_size=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch2(data, batch_size=10).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch2(data, batch_size=100).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch2(data, batch_size=1000).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X = meanshift_torch2(data, batch_size=6000).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(centroids+2, X, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean shift in scikit-learn\n",
    "\n",
    "Of course, sklearn also offers `MeanShift`.\n",
    "Let's see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = MeanShift()\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a faster than our naive implementation, but much slower than the GPU version.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Keep in mind that this demo is not saying that A is faster than B.\n",
    "It rather shows that you can use PyTorch in fun ways!\n",
    "\n",
    "Ref:\n",
    "- https://pytorch.org/docs/stable/notes/broadcasting.html\n",
    "- https://pytorch.org/docs/stable/notes/cuda.html\n",
    "- https://github.com/fastai/fastai/blob/master/tutorials/meanshift.ipynb"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
